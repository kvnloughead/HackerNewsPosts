{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # An Exploration of Hacker News Posts\n",
    " #### A DataQuest Guided Project\n",
    "\n",
    "### 1 Introduction\n",
    "\n",
    "This notebook is a small exploration of the Hacker News (HN) Posts dataset found at [kaggle](https://www.kaggle.com/hacker-news/hacker-news-posts/home).   The project appears before the DataQuest curriculum begins to cover `numpy` and `pandas`, so I won't be using those libraries.   \n",
    "\n",
    "The dataset consists of a collection of information pertaining to posts made to HN.  We are particularly interested in the subset of posts whose titles begin with the phrases \"Ask HN\" or \"Show HN\".  More specifically, we are interested in which sorts of posts garner the most comments.\n",
    "\n",
    "Later in the project, we will examine these posts more closely to find the times of day that provide maximal comment attraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Setup\n",
    "\n",
    "We start by loading and reading the csv file into a list of lists `hn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'] \n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'] \n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'] \n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n",
    "with open('hacker_news.csv') as fp:\n",
    "    hn = list(reader(fp))    \n",
    "\n",
    "for row in hn[:5]:\n",
    "    print(row, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we separate the `headers` from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is a bit beyond the project's scope, but I am going to write a simple object oriented interface for the rows (posts) in `hn`.  Just to ease my accessing of the columns.  I will instantiate a new version of `hn` called `HNews` which will be a list of `Post` objects as defined in the next cell.  We will use HNews as our dataset throughout the remainder of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post(object):\n",
    "\n",
    "    def __init__(self, _id, title, url, num_points, num_comments, author, \n",
    "                 created_at):\n",
    "        self.id = _id\n",
    "        self.title = title\n",
    "        self.url = url\n",
    "        self.num_points = int(num_points)\n",
    "        self.num_comments = int(num_comments)\n",
    "        self.author = author\n",
    "        self.created_at = created_at  \n",
    "        self.post_time = dt.datetime.strptime(self.created_at, \"%m/%d/%Y %H:%M\")\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Tried to do this by accessing attributes from dir and the evaluating\n",
    "        'self.{}'.format(attr) for each, but was told that self wasn't defined.\n",
    "        \"\"\"\n",
    "        attrs = [self.id, self.title, self.url, self.num_points,\n",
    "                 self.num_comments, self.author, self.created_at]\n",
    "        return str([str(attr) for attr in attrs])\n",
    "    \n",
    "    __repr__ = __str__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HNews = []\n",
    "for row in hn:\n",
    "    post = Post(*(row[i] for i in range(7)))\n",
    "    HNews.append(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Data Cleaning and Organization\n",
    "\n",
    "The next cell splits the posts into three categories: those beginning with `Ask HN`, those beginning with `Show HN` and everything else.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']] \n",
      "\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']] \n",
      "\n",
      "[['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']] \n",
      "\n",
      "Number of Ask HN Posts 1744\n",
      "Number of Show HN Posts 1162\n",
      "Number of Other Posts 17193\n"
     ]
    }
   ],
   "source": [
    "ask_posts, show_posts, other_posts = [], [], []\n",
    "\n",
    "for post in HNews:\n",
    "    if post.title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif post.title.lower().startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print(ask_posts[:2], \"\\n\")\n",
    "print(show_posts[:2], \"\\n\")\n",
    "print(other_posts[:2], \"\\n\")\n",
    "\n",
    "print(\"Number of Ask HN Posts\", len(ask_posts))\n",
    "print(\"Number of Show HN Posts\", len(show_posts))\n",
    "print(\"Number of Other Posts\", len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's now compute the average number of comments for `Ask` and for `Show` posts.  I'll compute the same result for `Other` posts, and all posts, for completeness sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Comments per Type of Post\n",
      "\n",
      "   Ask Posts:           14.038417431192661\n",
      "   Show Posts:          10.31669535283993\n",
      "   Other Posts:         26.8730371059672\n",
      "   All Posts:           24.80228855721393\n"
     ]
    }
   ],
   "source": [
    "def compute_avg_comments(posts):\n",
    "    \"\"\"Computes average number of comments for a list of Post objects.\"\"\"\n",
    "    total_comments = sum([post.num_comments for post in posts])\n",
    "    return total_comments / len(posts)\n",
    "\n",
    "avg_ask_comments = compute_avg_comments(ask_posts)\n",
    "avg_show_comments = compute_avg_comments(show_posts)\n",
    "avg_other_comments = compute_avg_comments(other_posts)\n",
    "avg_all_comments = compute_avg_comments(HNews)\n",
    "\n",
    "print(\"Average Number of Comments per Type of Post\\n\")\n",
    "print(\"  \", \"Ask Posts:\".ljust(20), avg_ask_comments)\n",
    "print(\"  \", \"Show Posts:\".ljust(20), avg_show_comments)\n",
    "print(\"  \", \"Other Posts:\".ljust(20), avg_other_comments)\n",
    "print(\"  \", \"All Posts:\".ljust(20), avg_all_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that, neither `Ask` nor `Show` posts are big comment attractors, netting roughly half as many comments as an arbitrary post would.  If racking up the comments is our desire, we should consider posting something else.\n",
    "\n",
    "Compared to each other, though, we see that `Ask` posts recieve on average 40% more comments than `Show` posts.  This doesn't seem particularly surprising, as the former are actively soliciting responses.  The remainder of this notebook will focus on these `Ask HN` posts, but one could make similar analyses for the other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Analysis of Ask Post Comments with Respect to Time of Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue by looking at the number of comments for a given type of post with respect to the time of the day at which the post was created, using the `post_time` datetime attribute of our `Post` class.  We will compute a frequency dictionary for comments by the hour of creation for each of our different types of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqency(dataset):\n",
    "    counts_by_hour = {}\n",
    "    comments_by_hour = {}\n",
    "    for post in dataset:\n",
    "        hour = post.post_time.hour\n",
    "        counts_by_hour[hour] = counts_by_hour.get(hour, 0) + 1\n",
    "        comments_by_hour[hour] = comments_by_hour.get(hour, 0) + post.num_comments\n",
    "    return counts_by_hour, comments_by_hour\n",
    "    \n",
    "def get_average_comments_by_hour(dataset):\n",
    "    counts, comments = get_freqency(dataset)\n",
    "    return {hr : comments[hr]/counts[hr] for hr in range(24)}\n",
    "\n",
    "show_avg_comments_hourly = get_average_comments_by_hour(show_posts)\n",
    "other_avg_comments_hourly = get_average_comments_by_hour(other_posts)\n",
    "all_avg_comments_hourly = get_average_comments_by_hour(HNews)\n",
    "\n",
    "ask_avg_comments_hourly = get_average_comments_by_hour(ask_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 8.127272727272727,\n",
       " 1: 11.383333333333333,\n",
       " 2: 23.810344827586206,\n",
       " 3: 7.796296296296297,\n",
       " 4: 7.170212765957447,\n",
       " 5: 10.08695652173913,\n",
       " 6: 9.022727272727273,\n",
       " 7: 7.852941176470588,\n",
       " 8: 10.25,\n",
       " 9: 5.5777777777777775,\n",
       " 10: 13.440677966101696,\n",
       " 11: 11.051724137931034,\n",
       " 12: 9.41095890410959,\n",
       " 13: 14.741176470588234,\n",
       " 14: 13.233644859813085,\n",
       " 15: 38.5948275862069,\n",
       " 16: 16.796296296296298,\n",
       " 17: 11.46,\n",
       " 18: 13.20183486238532,\n",
       " 19: 10.8,\n",
       " 20: 21.525,\n",
       " 21: 16.009174311926607,\n",
       " 22: 6.746478873239437,\n",
       " 23: 7.985294117647059}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_per_hour = ask_avg_comments_hourly\n",
    "avg_per_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we sort our results with respect to the number of comments, and display our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Top 5 Hours for Ask HN Posts, by Comments Received       \n",
      "       --------------------------------------------------       \n",
      "       Hour of Posting          Average Number of Comments  \n",
      "       ===============          ==========================  \n",
      "            15:00                         38.59             \n",
      "             2:00                         23.81             \n",
      "            20:00                         21.52             \n",
      "            16:00                         16.80             \n",
      "            21:00                         16.01             \n"
     ]
    }
   ],
   "source": [
    "sorted_hours = sorted(avg_per_hour, key=lambda hour : avg_per_hour[hour],\n",
    "                      reverse=True)\n",
    "sorted_ask_results = [[hour, avg_per_hour[hour]] for hour in sorted_hours]\n",
    "\n",
    "print(\"Top 5 Hours for Ask HN Posts, by Comments Received\".center(64))\n",
    "print(\"--------------------------------------------------\".center(64))\n",
    "print(\"Hour of Posting\".center(30) + \"Average Number of Comments\".center(30))\n",
    "print(\"===============\".center(30) + \"==========================\".center(30))\n",
    "\n",
    "for row in sorted_ask_results[:5]:\n",
    "    print(\"{}:00\".format(row[0]).center(30) + \"{:.2f}\".format(row[1]).center(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our results, and since the times given are in my own time zone (Eastern Standard, per the dataset's [description](https://www.kaggle.com/hacker-news/hacker-news-posts/home)), it seem that 3:00 p.m. would be the best time for me to attract comments with an `Ask HN` post.  Good to know.\n",
    "\n",
    "Of the 5 best times shown above, two are in the afternoon (3p and 4p), while two are in the evening (8p and 9p), in my time zone at least.  These are all quite convenient for me as an East Coast American and could suggest that many posters (and commenters) on Hacker News network are from this time zone, which would not be too surprising.  But I am sure there is much more to it than this.\n",
    "\n",
    "For instance, the West Coast of the US, I would expect, would also be a big driver of posts and comments on HN.  The four mentioned peak times correspond to 12p, 1p, 5p and 6p, respectively.  Lunch time and dinner time, respectively.  Put down your phone's and eat a nice meal for once, California!  Spend some time with friends and family!\n",
    "\n",
    "But of course, us Americans are not the only users of Hacker News.  In fact, country of origin of these posts would make for some interesting further analysis.  And I expect that many of the posts made around 2:00 am Eastern Standard, and many of the immediate comments these posts garner, would originate outside the states.  Although Hackers stereotypically do keep odd hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
